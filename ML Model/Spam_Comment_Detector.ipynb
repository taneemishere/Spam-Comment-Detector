{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psy = pd.read_csv('Youtube01-Psy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_psy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_psy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 columns and 350 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    350\n",
       "AUTHOR        350\n",
       "DATE          350\n",
       "CONTENT       350\n",
       "CLASS         350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_psy.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Null values present here ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp = pd.read_csv('Youtube02-KatyPerry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12pgdhovmrktzm3i23es5d5junftft3f</td>\n",
       "      <td>lekanaVEVO1</td>\n",
       "      <td>2014-07-22T15:27:50</td>\n",
       "      <td>i love this so much. AND also I Generate Free ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13yx345uxepetggz04ci5rjcxeohzlrtf4</td>\n",
       "      <td>Pyunghee</td>\n",
       "      <td>2014-07-27T01:57:16</td>\n",
       "      <td>http://www.billboard.com/articles/columns/pop-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k</td>\n",
       "      <td>Erica Ross</td>\n",
       "      <td>2014-07-27T02:51:43</td>\n",
       "      <td>Hey guys! Please join me in my fight to help a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jcjuovxbwfr0ge04cev2ipsjdfdurwck</td>\n",
       "      <td>Aviel Haimov</td>\n",
       "      <td>2014-08-01T12:27:48</td>\n",
       "      <td>http://psnboss.com/?ref=2tGgp3pV6L this is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k</td>\n",
       "      <td>John Bello</td>\n",
       "      <td>2014-08-01T21:04:03</td>\n",
       "      <td>Hey everyone. Watch this trailer!!!!!!!!  http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID        AUTHOR                 DATE  \\\n",
       "0      z12pgdhovmrktzm3i23es5d5junftft3f   lekanaVEVO1  2014-07-22T15:27:50   \n",
       "1    z13yx345uxepetggz04ci5rjcxeohzlrtf4      Pyunghee  2014-07-27T01:57:16   \n",
       "2  z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k    Erica Ross  2014-07-27T02:51:43   \n",
       "3    z13jcjuovxbwfr0ge04cev2ipsjdfdurwck  Aviel Haimov  2014-08-01T12:27:48   \n",
       "4  z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k    John Bello  2014-08-01T21:04:03   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0  i love this so much. AND also I Generate Free ...      1  \n",
       "1  http://www.billboard.com/articles/columns/pop-...      1  \n",
       "2  Hey guys! Please join me in my fight to help a...      1  \n",
       "3  http://psnboss.com/?ref=2tGgp3pV6L this is the...      1  \n",
       "4  Hey everyone. Watch this trailer!!!!!!!!  http...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    350\n",
       "AUTHOR        350\n",
       "DATE          350\n",
       "CONTENT       350\n",
       "CLASS         350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Null values present here also ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lmfao = pd.read_csv('Youtube03-LMFAO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k</td>\n",
       "      <td>Corey Wilson</td>\n",
       "      <td>2015-05-28T21:39:52.376000</td>\n",
       "      <td>&lt;a href=\"http://www.youtube.com/watch?v=KQ6zr6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z124jvczaz3dxhnbc04cffk43oiugj25yzo0k</td>\n",
       "      <td>Epic Gaming</td>\n",
       "      <td>2015-05-28T20:07:20.610000</td>\n",
       "      <td>wierd but funny﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13tczjy5xj0vjmu5231unho1ofey5zdk</td>\n",
       "      <td>LaS Music</td>\n",
       "      <td>2015-05-28T19:23:35.355000</td>\n",
       "      <td>Hey guys, I&amp;#39;m a human.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13tzr0hdpnayhqqc04cd3zqqqjkf3ngckk0k</td>\n",
       "      <td>Cheryl Fox</td>\n",
       "      <td>2015-05-28T17:49:35.294000</td>\n",
       "      <td>Party Rock....lol...who wants to shuffle!!!﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z12pcvix4zedcjvyb04ccr1r0mr2g5xwyng0k</td>\n",
       "      <td>PATRICK_TW</td>\n",
       "      <td>2015-05-28T16:28:26.818000</td>\n",
       "      <td>Party rock﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID        AUTHOR  \\\n",
       "0  z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k  Corey Wilson   \n",
       "1  z124jvczaz3dxhnbc04cffk43oiugj25yzo0k   Epic Gaming   \n",
       "2      z13tczjy5xj0vjmu5231unho1ofey5zdk     LaS Music   \n",
       "3  z13tzr0hdpnayhqqc04cd3zqqqjkf3ngckk0k    Cheryl Fox   \n",
       "4  z12pcvix4zedcjvyb04ccr1r0mr2g5xwyng0k    PATRICK_TW   \n",
       "\n",
       "                         DATE  \\\n",
       "0  2015-05-28T21:39:52.376000   \n",
       "1  2015-05-28T20:07:20.610000   \n",
       "2  2015-05-28T19:23:35.355000   \n",
       "3  2015-05-28T17:49:35.294000   \n",
       "4  2015-05-28T16:28:26.818000   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0  <a href=\"http://www.youtube.com/watch?v=KQ6zr6...      0  \n",
       "1                                   wierd but funny﻿      0  \n",
       "2  Hey guys, I&#39;m a human.<br /><br /><br />Bu...      1  \n",
       "3       Party Rock....lol...who wants to shuffle!!!﻿      0  \n",
       "4                                        Party rock﻿      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lmfao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lmfao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    438\n",
       "AUTHOR        438\n",
       "DATE          438\n",
       "CONTENT       438\n",
       "CLASS         438\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lmfao.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Null values present here also ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_em = pd.read_csv('Youtube04-Eminem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12rwfnyyrbsefonb232i5ehdxzkjzjs2</td>\n",
       "      <td>Lisa Wellas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+447935454150 lovely girl talk to me xxx﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04</td>\n",
       "      <td>jason graham</td>\n",
       "      <td>2015-05-29T02:26:10.652000</td>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13vsfqirtavjvu0t22ezrgzyorwxhpf3</td>\n",
       "      <td>Ajkal Khan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12wjzc4eprnvja4304cgbbizuved35wxcs</td>\n",
       "      <td>Dakota Taylor</td>\n",
       "      <td>2015-05-29T02:13:07.810000</td>\n",
       "      <td>Cool﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13xjfr42z3uxdz2223gx5rrzs3dt5hna</td>\n",
       "      <td>Jihad Naser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello I&amp;#39;am from Palastine﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMMENT_ID         AUTHOR  \\\n",
       "0    z12rwfnyyrbsefonb232i5ehdxzkjzjs2    Lisa Wellas   \n",
       "1  z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04   jason graham   \n",
       "2    z13vsfqirtavjvu0t22ezrgzyorwxhpf3     Ajkal Khan   \n",
       "3  z12wjzc4eprnvja4304cgbbizuved35wxcs  Dakota Taylor   \n",
       "4    z13xjfr42z3uxdz2223gx5rrzs3dt5hna    Jihad Naser   \n",
       "\n",
       "                         DATE  \\\n",
       "0                         NaN   \n",
       "1  2015-05-29T02:26:10.652000   \n",
       "2                         NaN   \n",
       "3  2015-05-29T02:13:07.810000   \n",
       "4                         NaN   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0          +447935454150 lovely girl talk to me xxx﻿      1  \n",
       "1    I always end up coming back to this song<br />﻿      0  \n",
       "2  my sister just received over 6,500 new <a rel=...      1  \n",
       "3                                              Cool﻿      0  \n",
       "4                     Hello I&#39;am from Palastine﻿      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_em.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    448\n",
       "AUTHOR        448\n",
       "DATE          203\n",
       "CONTENT       448\n",
       "CLASS         448\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_em.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some missing values are there in the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sk = pd.read_csv('Youtube05-Shakira.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
       "      <td>dharma pal</td>\n",
       "      <td>2015-05-29T02:30:18.971000</td>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
       "      <td>Tiza Arellano</td>\n",
       "      <td>2015-05-29T00:14:48.748000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
       "      <td>Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿</td>\n",
       "      <td>2015-05-28T21:00:08.607000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12icv3ysqvlwth2c23eddlykyqut5z1h</td>\n",
       "      <td>Eric Gonzalez</td>\n",
       "      <td>2015-05-28T20:47:12.193000</td>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133stly3kete3tly22petvwdpmghrlli</td>\n",
       "      <td>Analena López</td>\n",
       "      <td>2015-05-28T17:08:29.827000</td>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID                              AUTHOR  \\\n",
       "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
       "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
       "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
       "3      z12icv3ysqvlwth2c23eddlykyqut5z1h                       Eric Gonzalez   \n",
       "4      z133stly3kete3tly22petvwdpmghrlli                       Analena López   \n",
       "\n",
       "                         DATE  \\\n",
       "0  2015-05-29T02:30:18.971000   \n",
       "1  2015-05-29T00:14:48.748000   \n",
       "2  2015-05-28T21:00:08.607000   \n",
       "3  2015-05-28T20:47:12.193000   \n",
       "4  2015-05-28T17:08:29.827000   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0                                         Nice song﻿      0  \n",
       "1                                      I love song ﻿      0  \n",
       "2                                      I love song ﻿      0  \n",
       "3  860,000,000 lets make it first female to reach...      0  \n",
       "4                      shakira is best for worldcup﻿      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    370\n",
       "AUTHOR        370\n",
       "DATE          370\n",
       "CONTENT       370\n",
       "CLASS         370\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sk.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to merge all the datasets into one so that we'll have one large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [df_psy, df_kp, df_lmfao, df_em, df_sk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the dataset have the same column names luckily, COMMENT_ID, AUTHOR, DATE, CONTENT, CLASS by this it is easy for us to use the .concat command by pandas to that it will concatenate all the data according to their respective column starting from the \"df_psy\" up to the \"df_sk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1956, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1956\n",
       "AUTHOR        1956\n",
       "DATE          1711\n",
       "CONTENT       1956\n",
       "CLASS         1956\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look we've now a total of 1956 rows, that is sum up from the separately of 5 datasets.\n",
    "The DATE column was having some missing values in the 'Youtube04-Eminem' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>_2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA</td>\n",
       "      <td>Katie Mettam</td>\n",
       "      <td>2013-07-13T13:27:39.441000</td>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>_2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI</td>\n",
       "      <td>Sabina Pearson-Smith</td>\n",
       "      <td>2013-07-13T13:14:30.021000</td>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>_2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs</td>\n",
       "      <td>jeffrey jules</td>\n",
       "      <td>2013-07-13T12:09:31.188000</td>\n",
       "      <td>wow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>_2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0</td>\n",
       "      <td>Aishlin Maciel</td>\n",
       "      <td>2013-07-13T11:17:52.308000</td>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>_2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA</td>\n",
       "      <td>Latin Bosch</td>\n",
       "      <td>2013-07-12T22:33:27.916000</td>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COMMENT_ID                AUTHOR  \\\n",
       "0    LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU             Julius NM   \n",
       "1    LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A           adam riyati   \n",
       "2    LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8      Evgeny Murashkin   \n",
       "3            z13jhp0bxqncu512g22wvzkasxmvvzjaz04       ElNino Melendez   \n",
       "4            z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                GsMega   \n",
       "..                                           ...                   ...   \n",
       "365  _2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA          Katie Mettam   \n",
       "366  _2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI  Sabina Pearson-Smith   \n",
       "367  _2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs         jeffrey jules   \n",
       "368  _2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0        Aishlin Maciel   \n",
       "369  _2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA           Latin Bosch   \n",
       "\n",
       "                           DATE  \\\n",
       "0           2013-11-07T06:20:48   \n",
       "1           2013-11-07T12:37:15   \n",
       "2           2013-11-08T17:34:21   \n",
       "3           2013-11-09T08:28:43   \n",
       "4           2013-11-10T16:05:38   \n",
       "..                          ...   \n",
       "365  2013-07-13T13:27:39.441000   \n",
       "366  2013-07-13T13:14:30.021000   \n",
       "367  2013-07-13T12:09:31.188000   \n",
       "368  2013-07-13T11:17:52.308000   \n",
       "369  2013-07-12T22:33:27.916000   \n",
       "\n",
       "                                               CONTENT  CLASS  \n",
       "0    Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1    Hey guys check out my new channel and our firs...      1  \n",
       "2               just for test I have to say murdev.com      1  \n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "..                                                 ...    ...  \n",
       "365  I love this song because we sing it at Camp al...      0  \n",
       "366  I love this song for two reasons: 1.it is abou...      0  \n",
       "367                                                wow      0  \n",
       "368                            Shakira u are so wiredo      0  \n",
       "369                         Shakira is the best dancer      0  \n",
       "\n",
       "[1956 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning keys to every datasets' comments in the concatenated dataset so that if we need to see the comments of a specific person or say dataset it would be easy for us to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['psy', 'kattyPerry', 'lmfao', 'eminem', 'shakira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default the keys parameter is set to none\n",
    "final_dataframe = pd.concat(data_frames, keys=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1956\n",
       "AUTHOR        1956\n",
       "DATE          1711\n",
       "CONTENT       1956\n",
       "CLASS         1956\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing is changed with the dataset's columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we can see the comments of Katty Perry from the final large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12pgdhovmrktzm3i23es5d5junftft3f</td>\n",
       "      <td>lekanaVEVO1</td>\n",
       "      <td>2014-07-22T15:27:50</td>\n",
       "      <td>i love this so much. AND also I Generate Free ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13yx345uxepetggz04ci5rjcxeohzlrtf4</td>\n",
       "      <td>Pyunghee</td>\n",
       "      <td>2014-07-27T01:57:16</td>\n",
       "      <td>http://www.billboard.com/articles/columns/pop-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k</td>\n",
       "      <td>Erica Ross</td>\n",
       "      <td>2014-07-27T02:51:43</td>\n",
       "      <td>Hey guys! Please join me in my fight to help a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jcjuovxbwfr0ge04cev2ipsjdfdurwck</td>\n",
       "      <td>Aviel Haimov</td>\n",
       "      <td>2014-08-01T12:27:48</td>\n",
       "      <td>http://psnboss.com/?ref=2tGgp3pV6L this is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k</td>\n",
       "      <td>John Bello</td>\n",
       "      <td>2014-08-01T21:04:03</td>\n",
       "      <td>Hey everyone. Watch this trailer!!!!!!!!  http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>z12sjp3zgtqnvlysj23zuxxaolrvd1oj504</td>\n",
       "      <td>Kacy Cluley</td>\n",
       "      <td>2015-06-05T18:59:52</td>\n",
       "      <td>This song means so much to me thank you  soooo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>z132enrpoy35yxpoe04cjr4zur3jvbyq3xo0k</td>\n",
       "      <td>Kasia Fabisiewicz</td>\n",
       "      <td>2015-06-05T19:02:05</td>\n",
       "      <td>&amp;lt;3﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>z132jbmxfqm4fjysg23nwjfb2mv2vxnua</td>\n",
       "      <td>Decio Alves Martins</td>\n",
       "      <td>2015-06-05T19:29:20</td>\n",
       "      <td>KATY PERRY, I AM THE \"DÉCIO CABELO\", \"DECIO HA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>z12cdlswetvnejcri04cex0jfwy2u3tzj54</td>\n",
       "      <td>Rafi Hossain</td>\n",
       "      <td>2015-06-05T19:55:08</td>\n",
       "      <td>Honestly speaking except taylor swift and adel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>z120e5uautvcuper304ccf4bjrjugdpbwrc0k</td>\n",
       "      <td>moaz adnan</td>\n",
       "      <td>2015-06-05T20:01:23</td>\n",
       "      <td>who is going to reach the billion first : katy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                COMMENT_ID               AUTHOR  \\\n",
       "0        z12pgdhovmrktzm3i23es5d5junftft3f          lekanaVEVO1   \n",
       "1      z13yx345uxepetggz04ci5rjcxeohzlrtf4             Pyunghee   \n",
       "2    z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k           Erica Ross   \n",
       "3      z13jcjuovxbwfr0ge04cev2ipsjdfdurwck         Aviel Haimov   \n",
       "4    z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k           John Bello   \n",
       "..                                     ...                  ...   \n",
       "345    z12sjp3zgtqnvlysj23zuxxaolrvd1oj504          Kacy Cluley   \n",
       "346  z132enrpoy35yxpoe04cjr4zur3jvbyq3xo0k    Kasia Fabisiewicz   \n",
       "347      z132jbmxfqm4fjysg23nwjfb2mv2vxnua  Decio Alves Martins   \n",
       "348    z12cdlswetvnejcri04cex0jfwy2u3tzj54         Rafi Hossain   \n",
       "349  z120e5uautvcuper304ccf4bjrjugdpbwrc0k           moaz adnan   \n",
       "\n",
       "                    DATE                                            CONTENT  \\\n",
       "0    2014-07-22T15:27:50  i love this so much. AND also I Generate Free ...   \n",
       "1    2014-07-27T01:57:16  http://www.billboard.com/articles/columns/pop-...   \n",
       "2    2014-07-27T02:51:43  Hey guys! Please join me in my fight to help a...   \n",
       "3    2014-08-01T12:27:48  http://psnboss.com/?ref=2tGgp3pV6L this is the...   \n",
       "4    2014-08-01T21:04:03  Hey everyone. Watch this trailer!!!!!!!!  http...   \n",
       "..                   ...                                                ...   \n",
       "345  2015-06-05T18:59:52  This song means so much to me thank you  soooo...   \n",
       "346  2015-06-05T19:02:05                                             &lt;3﻿   \n",
       "347  2015-06-05T19:29:20  KATY PERRY, I AM THE \"DÉCIO CABELO\", \"DECIO HA...   \n",
       "348  2015-06-05T19:55:08  Honestly speaking except taylor swift and adel...   \n",
       "349  2015-06-05T20:01:23  who is going to reach the billion first : katy...   \n",
       "\n",
       "     CLASS  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "345      0  \n",
       "346      0  \n",
       "347      1  \n",
       "348      0  \n",
       "349      0  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.loc['kattyPerry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12pgdhovmrktzm3i23es5d5junftft3f</td>\n",
       "      <td>lekanaVEVO1</td>\n",
       "      <td>2014-07-22T15:27:50</td>\n",
       "      <td>i love this so much. AND also I Generate Free ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13yx345uxepetggz04ci5rjcxeohzlrtf4</td>\n",
       "      <td>Pyunghee</td>\n",
       "      <td>2014-07-27T01:57:16</td>\n",
       "      <td>http://www.billboard.com/articles/columns/pop-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k</td>\n",
       "      <td>Erica Ross</td>\n",
       "      <td>2014-07-27T02:51:43</td>\n",
       "      <td>Hey guys! Please join me in my fight to help a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jcjuovxbwfr0ge04cev2ipsjdfdurwck</td>\n",
       "      <td>Aviel Haimov</td>\n",
       "      <td>2014-08-01T12:27:48</td>\n",
       "      <td>http://psnboss.com/?ref=2tGgp3pV6L this is the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k</td>\n",
       "      <td>John Bello</td>\n",
       "      <td>2014-08-01T21:04:03</td>\n",
       "      <td>Hey everyone. Watch this trailer!!!!!!!!  http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID        AUTHOR                 DATE  \\\n",
       "0      z12pgdhovmrktzm3i23es5d5junftft3f   lekanaVEVO1  2014-07-22T15:27:50   \n",
       "1    z13yx345uxepetggz04ci5rjcxeohzlrtf4      Pyunghee  2014-07-27T01:57:16   \n",
       "2  z12lsjvi3wa5x1vwh04cibeaqnzrevxajw00k    Erica Ross  2014-07-27T02:51:43   \n",
       "3    z13jcjuovxbwfr0ge04cev2ipsjdfdurwck  Aviel Haimov  2014-08-01T12:27:48   \n",
       "4  z13qybua2yfydzxzj04cgfpqdt2syfx53ms0k    John Bello  2014-08-01T21:04:03   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0  i love this so much. AND also I Generate Free ...      1  \n",
       "1  http://www.billboard.com/articles/columns/pop-...      1  \n",
       "2  Hey guys! Please join me in my fight to help a...      1  \n",
       "3  http://psnboss.com/?ref=2tGgp3pV6L this is the...      1  \n",
       "4  Hey everyone. Watch this trailer!!!!!!!!  http...      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look in above code it print out the comments ralted to the key==kattyPerry. \n",
    "# And for confirmation I run this line of code\n",
    "df_kp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the final_dataframe into a csv file by the pandas method to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.to_csv('final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9780"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    object\n",
       "AUTHOR        object\n",
       "DATE          object\n",
       "CONTENT       object\n",
       "CLASS          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    0\n",
       "AUTHOR        0\n",
       "DATE          0\n",
       "CONTENT       0\n",
       "CLASS         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.isnull().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID      0\n",
       "AUTHOR          0\n",
       "DATE          245\n",
       "CONTENT         0\n",
       "CLASS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psy      0             2013-11-07T06:20:48\n",
       "         1             2013-11-07T12:37:15\n",
       "         2             2013-11-08T17:34:21\n",
       "         3             2013-11-09T08:28:43\n",
       "         4             2013-11-10T16:05:38\n",
       "                           ...            \n",
       "shakira  365    2013-07-13T13:27:39.441000\n",
       "         366    2013-07-13T13:14:30.021000\n",
       "         367    2013-07-13T12:09:31.188000\n",
       "         368    2013-07-13T11:17:52.308000\n",
       "         369    2013-07-12T22:33:27.916000\n",
       "Name: DATE, Length: 1956, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psy      0                 Julius NM\n",
       "         1               adam riyati\n",
       "         2          Evgeny Murashkin\n",
       "         3           ElNino Melendez\n",
       "         4                    GsMega\n",
       "                        ...         \n",
       "shakira  365            Katie Mettam\n",
       "         366    Sabina Pearson-Smith\n",
       "         367           jeffrey jules\n",
       "         368          Aishlin Maciel\n",
       "         369             Latin Bosch\n",
       "Name: AUTHOR, Length: 1956, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.AUTHOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As if look up the we can observe that from the contents, we'll classiy the comments as spam or not spam. \n",
    "Like the other attributes doesn't matter that much. As the one is name, we don't care about who is the author. Also in case of \n",
    "date it also doesn't matter like on which date it has been posted or something else.\n",
    "So for us the 'CONTENT' and the 'CLASS' columns are most important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = final_dataframe[['CONTENT', 'CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">psy</th>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CONTENT  CLASS\n",
       "psy 0  Huh, anyway check out this you[tube] channel: ...      1\n",
       "    1  Hey guys check out my new channel and our firs...      1\n",
       "    2             just for test I have to say murdev.com      1\n",
       "    3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1\n",
       "    4            watch?v=vtaRGgvGtWQ   Check this out .﻿      1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONTENT    1956\n",
       "CLASS      1956\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONTENT', 'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = data_df['CONTENT']\n",
    "data_label = data_df['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Packages For Vectorization of Text For Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features with the CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data (feature) which is in corpus \n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '002',\n",
       " '018',\n",
       " '02',\n",
       " '034',\n",
       " '04',\n",
       " '047000',\n",
       " '05',\n",
       " '053012',\n",
       " '0687119038',\n",
       " '08',\n",
       " '09',\n",
       " '0cb8qfjaa',\n",
       " '0d878a889c',\n",
       " '0dbhjzdw0lbsjbi40gxm0d0p5krhv8xinqli53__wqbahs8zx4mjhw5vwrkpxfoeks',\n",
       " '0laviqu2b',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000000',\n",
       " '1000000000',\n",
       " '100000415527985',\n",
       " '100005244783212',\n",
       " '100007085325116',\n",
       " '10001',\n",
       " '100877300245414',\n",
       " '101721377578919894134',\n",
       " '10200253113705769',\n",
       " '1030',\n",
       " '104999962146104962510',\n",
       " '10626048',\n",
       " '10626835',\n",
       " '106865403',\n",
       " '107297364',\n",
       " '1073741825',\n",
       " '1073741828',\n",
       " '1073741830',\n",
       " '1073741943',\n",
       " '108k',\n",
       " '109',\n",
       " '10b35481',\n",
       " '11',\n",
       " '1111',\n",
       " '1111111111111111111',\n",
       " '111719098841907',\n",
       " '111982027348137311818',\n",
       " '112720997191206369631',\n",
       " '11cpwb',\n",
       " '11th',\n",
       " '12',\n",
       " '123',\n",
       " '124',\n",
       " '124923004',\n",
       " '126',\n",
       " '127',\n",
       " '128gb',\n",
       " '12year',\n",
       " '13',\n",
       " '13017194',\n",
       " '131275322914',\n",
       " '131338190916',\n",
       " '1337',\n",
       " '1340488',\n",
       " '1340489',\n",
       " '1340490',\n",
       " '1340491',\n",
       " '1340492',\n",
       " '1340493',\n",
       " '1340494',\n",
       " '1340499',\n",
       " '1340500',\n",
       " '1340502',\n",
       " '1340503',\n",
       " '1340504',\n",
       " '1340517',\n",
       " '1340518',\n",
       " '1340519',\n",
       " '1340520',\n",
       " '1340521',\n",
       " '1340522',\n",
       " '1340523',\n",
       " '1340524',\n",
       " '134470083389909',\n",
       " '14',\n",
       " '1408122684',\n",
       " '1415297812',\n",
       " '1442646731',\n",
       " '1446084',\n",
       " '1461302180794905',\n",
       " '1495323920744243',\n",
       " '1496241863981208',\n",
       " '1496273723978022',\n",
       " '1498561870415874',\n",
       " '14gkvdo',\n",
       " '15',\n",
       " '16',\n",
       " '161620527267482',\n",
       " '16gb',\n",
       " '17',\n",
       " '171183229277',\n",
       " '1727483389',\n",
       " '17yr',\n",
       " '18',\n",
       " '19',\n",
       " '19255',\n",
       " '1990',\n",
       " '19924',\n",
       " '1b',\n",
       " '1bi',\n",
       " '1billiom',\n",
       " '1billion',\n",
       " '1bsefqe',\n",
       " '1fhenqx1twqm153v2ptayiejnealahzvem',\n",
       " '1firo',\n",
       " '1hmvtx',\n",
       " '1k',\n",
       " '1m',\n",
       " '1m00s',\n",
       " '1min',\n",
       " '20',\n",
       " '200',\n",
       " '2004',\n",
       " '2005',\n",
       " '2008',\n",
       " '2009',\n",
       " '200k',\n",
       " '200mm',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2012430',\n",
       " '2012bitches',\n",
       " '2013',\n",
       " '2014',\n",
       " '201470069872822',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '207230212795137',\n",
       " '21',\n",
       " '210',\n",
       " '2177367',\n",
       " '229508',\n",
       " '23',\n",
       " '23active',\n",
       " '23awesome',\n",
       " '23eminem',\n",
       " '23everydayimvaping',\n",
       " '23giraffebruuh',\n",
       " '23king',\n",
       " '23kinglothedancer',\n",
       " '23lmfao',\n",
       " '23lovethewayyoulie',\n",
       " '23rapgod',\n",
       " '23rt',\n",
       " '23share',\n",
       " '24',\n",
       " '24398',\n",
       " '243a',\n",
       " '247',\n",
       " '25',\n",
       " '250',\n",
       " '25000',\n",
       " '251638183951',\n",
       " '25874',\n",
       " '25th',\n",
       " '26',\n",
       " '26032883',\n",
       " '26t22',\n",
       " '27',\n",
       " '279',\n",
       " '28',\n",
       " '29',\n",
       " '2asfn9shghk',\n",
       " '2b',\n",
       " '2b4wywphi8c',\n",
       " '2billion',\n",
       " '2f',\n",
       " '2fen',\n",
       " '2flist_of_most_viewed_youtube_videos',\n",
       " '2fwiki',\n",
       " '2m19s',\n",
       " '2nd',\n",
       " '2parale',\n",
       " '2tggp3pv6l',\n",
       " '2x10',\n",
       " '2zme8f',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '301',\n",
       " '302703146601369',\n",
       " '30th',\n",
       " '313327',\n",
       " '313454548839369',\n",
       " '315',\n",
       " '31st',\n",
       " '320',\n",
       " '322',\n",
       " '327568907427561',\n",
       " '32gb',\n",
       " '33',\n",
       " '333',\n",
       " '333607726823679',\n",
       " '333608120156973',\n",
       " '33gxrf',\n",
       " '342',\n",
       " '35',\n",
       " '360',\n",
       " '365',\n",
       " '36loseweight',\n",
       " '385',\n",
       " '387',\n",
       " '3873',\n",
       " '389088',\n",
       " '39',\n",
       " '390',\n",
       " '390875584405933',\n",
       " '391725794320912',\n",
       " '3a',\n",
       " '3bie',\n",
       " '3bkeywords',\n",
       " '3bqid',\n",
       " '3bsr',\n",
       " '3d',\n",
       " '3m',\n",
       " '3m40s',\n",
       " '3m57s',\n",
       " '3rd',\n",
       " '40',\n",
       " '4000',\n",
       " '4000dollars',\n",
       " '40beuutvu2zkxk4utgpz8k',\n",
       " '41',\n",
       " '421',\n",
       " '43',\n",
       " '433',\n",
       " '4344749',\n",
       " '4436607',\n",
       " '4477063',\n",
       " '447935454150',\n",
       " '4483179854075',\n",
       " '448800865296855',\n",
       " '45',\n",
       " '4500',\n",
       " '46',\n",
       " '4604617',\n",
       " '476000',\n",
       " '48051',\n",
       " '482',\n",
       " '484',\n",
       " '490',\n",
       " '492',\n",
       " '4e',\n",
       " '4g',\n",
       " '4gb',\n",
       " '4m11s',\n",
       " '4netjobs',\n",
       " '4s',\n",
       " '4shared',\n",
       " '4snjqp',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '500k',\n",
       " '500m',\n",
       " '505b0232',\n",
       " '5094',\n",
       " '50k',\n",
       " '510',\n",
       " '515',\n",
       " '521',\n",
       " '5242575',\n",
       " '5277478',\n",
       " '5287',\n",
       " '53331',\n",
       " '5337555197',\n",
       " '53481',\n",
       " '543627485763966',\n",
       " '55',\n",
       " '550',\n",
       " '5575096797',\n",
       " '55mm',\n",
       " '566',\n",
       " '57',\n",
       " '58',\n",
       " '5800',\n",
       " '5af506e1',\n",
       " '5bgkg2iwphzohwaeuesrwnegqg_labco7rw9wfx8hao',\n",
       " '5c',\n",
       " '5c2f',\n",
       " '5ggs_m_9ma3ti40fs6mvpics',\n",
       " '5million',\n",
       " '5s',\n",
       " '5th',\n",
       " '5tu9gn1l310',\n",
       " '60',\n",
       " '600',\n",
       " '600m',\n",
       " '613000',\n",
       " '616375350',\n",
       " '6174122',\n",
       " '629',\n",
       " '629410220489046',\n",
       " '633807',\n",
       " '636',\n",
       " '6381501',\n",
       " '6401116',\n",
       " '661',\n",
       " '666',\n",
       " '674732645945877',\n",
       " '682',\n",
       " '694',\n",
       " '6_h0m5sayho',\n",
       " '6th',\n",
       " '700',\n",
       " '704682339621282',\n",
       " '710',\n",
       " '710000',\n",
       " '73231344',\n",
       " '733634264',\n",
       " '733949243353321',\n",
       " '734237113324534',\n",
       " '74',\n",
       " '750',\n",
       " '753',\n",
       " '754989901225153',\n",
       " '764484966942313',\n",
       " '775510675841486',\n",
       " '783',\n",
       " '79',\n",
       " '7in',\n",
       " '7k',\n",
       " '800',\n",
       " '82',\n",
       " '821',\n",
       " '824',\n",
       " '8252267209931889',\n",
       " '832000',\n",
       " '84',\n",
       " '85',\n",
       " '851',\n",
       " '857',\n",
       " '860',\n",
       " '868',\n",
       " '8692160',\n",
       " '87',\n",
       " '870',\n",
       " '88',\n",
       " '884',\n",
       " '8851222',\n",
       " '898',\n",
       " '89___',\n",
       " '89c',\n",
       " '89iyec7nrwp5nytno5u7amhvmflutggl',\n",
       " '8a',\n",
       " '8bit',\n",
       " '90',\n",
       " '90000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000',\n",
       " '902099',\n",
       " '9082175',\n",
       " '9107',\n",
       " '911',\n",
       " '920',\n",
       " '9277547',\n",
       " '936868579660284',\n",
       " '937732262907249',\n",
       " '940',\n",
       " '950',\n",
       " '969',\n",
       " '999999999',\n",
       " '9bzkp7q19f0',\n",
       " '9gag',\n",
       " '9nl',\n",
       " '_0f9fa8aa',\n",
       " '__',\n",
       " '______________________',\n",
       " '______________________________',\n",
       " '__killuminati94',\n",
       " '_bzszz',\n",
       " '_chris_cz',\n",
       " '_fphgk5zllsvdqv0zuf0mb',\n",
       " '_gibu',\n",
       " '_o3h',\n",
       " '_ry6f57sprnd2xv',\n",
       " '_self',\n",
       " '_thqbeum69aqup1ih',\n",
       " '_trksid',\n",
       " '_vlczzrg8vgctlpsd9ongewhj8',\n",
       " 'a0qouc7q48v3_qiaaabpugaaacsqar0_vgoqwqxjmpuyvkosf3k',\n",
       " 'a7',\n",
       " 'aa',\n",
       " 'aaaaaaa',\n",
       " 'aaas',\n",
       " 'aavpwj9',\n",
       " 'abbas',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'abonner',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abusue',\n",
       " 'ac',\n",
       " 'acaer',\n",
       " 'acceptance',\n",
       " 'access',\n",
       " 'accessories',\n",
       " 'accidental',\n",
       " 'accomplished',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'acidic',\n",
       " 'aclk',\n",
       " 'acn2g',\n",
       " 'acoustic',\n",
       " 'acquire',\n",
       " 'acquiring',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actor',\n",
       " 'actorid',\n",
       " 'actors',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addicting',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'adele',\n",
       " 'adf',\n",
       " 'adhoc',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'admitting',\n",
       " 'adore',\n",
       " 'adoult',\n",
       " 'adroid',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adurl',\n",
       " 'advance',\n",
       " 'advertise',\n",
       " 'advertisements',\n",
       " 'advertisiments',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'affiliated',\n",
       " 'affiliateid',\n",
       " 'afflicted',\n",
       " 'afford',\n",
       " 'afiliati',\n",
       " 'afiliere',\n",
       " 'afqjcngkm',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'after',\n",
       " 'aftermath',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aiiima',\n",
       " 'aimbwbfqbzg',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'album',\n",
       " 'alcoholic',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alfred',\n",
       " 'ali',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'allways',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'alo',\n",
       " 'aloidia',\n",
       " 'alone',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alvar',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'amendment',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amiable',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anaconda',\n",
       " 'analyst',\n",
       " 'anand',\n",
       " 'ancestors',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'andrijamatf',\n",
       " 'android',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animation',\n",
       " 'animations',\n",
       " 'animator',\n",
       " 'anime',\n",
       " 'animes',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'anthem',\n",
       " 'antrobofficial',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'anywon',\n",
       " 'aod64_1ofc7seh_1pop',\n",
       " 'aplica',\n",
       " 'apocalypse',\n",
       " 'apologies',\n",
       " 'apostles',\n",
       " 'app',\n",
       " 'apparel',\n",
       " 'apparently',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'applied',\n",
       " 'applocker',\n",
       " 'appoints',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'apprecitate',\n",
       " 'approve',\n",
       " 'apps',\n",
       " 'arbitrate',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arguements',\n",
       " 'arive',\n",
       " 'arkglzjqup0',\n",
       " 'arm',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrogant',\n",
       " 'arrowgance',\n",
       " 'art',\n",
       " 'artady',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'as',\n",
       " 'aseris',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aslamu',\n",
       " 'aspiring',\n",
       " 'aspx',\n",
       " 'ass',\n",
       " 'assume',\n",
       " 'astauand',\n",
       " 'aswell',\n",
       " 'at',\n",
       " 'atlastatlas',\n",
       " 'attacks',\n",
       " 'attention',\n",
       " 'auburn',\n",
       " 'audio',\n",
       " 'audiojungle',\n",
       " 'audit',\n",
       " 'audition',\n",
       " 'auditiondetail_',\n",
       " 'auditioning',\n",
       " 'auditions',\n",
       " 'aunt',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'authenticviews',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'autotune',\n",
       " 'autotuned',\n",
       " 'avaaz',\n",
       " 'available',\n",
       " 'avicii',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'aways',\n",
       " 'awesom',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awesoooome',\n",
       " 'awesum',\n",
       " 'awful',\n",
       " 'awsome',\n",
       " 'axeljonssons',\n",
       " 'axiomatic',\n",
       " 'axy665',\n",
       " 'aye',\n",
       " 'ayyy',\n",
       " 'azerbaijan',\n",
       " 'b00ecvf93g',\n",
       " 'b00mppqhri',\n",
       " 'b3',\n",
       " 'b5',\n",
       " 'b5t',\n",
       " 'b7b',\n",
       " 'b8l',\n",
       " 'ba',\n",
       " 'baba',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bady',\n",
       " 'ball',\n",
       " 'ballad',\n",
       " 'balls',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bang',\n",
       " 'bangers',\n",
       " 'banging',\n",
       " 'bangladesh',\n",
       " 'barnesandnoble',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basically',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bd3721315',\n",
       " 'bdp',\n",
       " 'be',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beatboxing',\n",
       " 'beaties',\n",
       " 'beating',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'before',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beibs',\n",
       " 'being',\n",
       " 'belarus',\n",
       " 'belgique',\n",
       " 'belgium',\n",
       " 'believe',\n",
       " 'believemefilm',\n",
       " 'believer',\n",
       " 'believing',\n",
       " 'bella',\n",
       " 'belle',\n",
       " 'belly',\n",
       " 'below',\n",
       " 'belrus',\n",
       " 'beneath',\n",
       " 'bengal',\n",
       " 'bennett',\n",
       " 'berzerk',\n",
       " 'besloor',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betfair',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beutiful',\n",
       " 'beware',\n",
       " 'bf4',\n",
       " 'bg',\n",
       " 'bgq',\n",
       " 'bieber',\n",
       " 'big',\n",
       " 'bigboss286',\n",
       " 'bigelow',\n",
       " 'bigger',\n",
       " 'bighit',\n",
       " 'bikini',\n",
       " 'bil',\n",
       " 'bilion',\n",
       " 'billboard',\n",
       " 'billie',\n",
       " 'billion',\n",
       " 'billions',\n",
       " 'billon',\n",
       " 'bills',\n",
       " 'binbox',\n",
       " 'bing',\n",
       " 'birtgday',\n",
       " 'birthday',\n",
       " 'bisexual',\n",
       " 'bishopsgravemarker',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitcoins',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'blanc',\n",
       " 'blank',\n",
       " 'blast',\n",
       " 'bleach',\n",
       " 'bless',\n",
       " 'blessing',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogfa',\n",
       " 'blogspot',\n",
       " 'blond',\n",
       " 'blonde',\n",
       " 'blow',\n",
       " 'blows',\n",
       " 'blue',\n",
       " 'blushing',\n",
       " 'boa',\n",
       " 'boaconic',\n",
       " 'bocilile',\n",
       " 'body',\n",
       " 'bogdan',\n",
       " 'bomb',\n",
       " 'bones',\n",
       " 'bonus',\n",
       " 'boobs',\n",
       " 'book',\n",
       " 'bookies',\n",
       " 'bookmakers',\n",
       " 'boomerul',\n",
       " 'boooobs',\n",
       " 'boost',\n",
       " 'border',\n",
       " 'borderlands',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'bother',\n",
       " 'bots',\n",
       " 'bottom',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxium',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'bps',\n",
       " 'br',\n",
       " 'brah',\n",
       " 'brain',\n",
       " 'brake',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'break',\n",
       " 'breaken',\n",
       " 'breaks',\n",
       " 'breath',\n",
       " 'brew',\n",
       " 'briefs',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brinkman',\n",
       " 'british',\n",
       " 'britishs',\n",
       " 'broken',\n",
       " 'brooooo',\n",
       " 'brother',\n",
       " 'brotherhood',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'brt0u5',\n",
       " 'brutally',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'bubblews',\n",
       " 'buchmair',\n",
       " 'bucket',\n",
       " 'bucks',\n",
       " 'buggti',\n",
       " 'build',\n",
       " 'bulgaria',\n",
       " 'bumps',\n",
       " 'bunch',\n",
       " 'burda',\n",
       " 'burder',\n",
       " 'burned',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busyglide',\n",
       " 'but',\n",
       " 'butalabs',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'butts',\n",
       " 'buy',\n",
       " 'buys',\n",
       " 'buzz',\n",
       " 'bv',\n",
       " 'bvm',\n",
       " 'bxrosr',\n",
       " 'by',\n",
       " 'c3',\n",
       " 'c349',\n",
       " 'ca',\n",
       " 'cabelo',\n",
       " 'cachebuster',\n",
       " 'cad',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'cameraman',\n",
       " 'camp',\n",
       " 'campid',\n",
       " 'can',\n",
       " 'canal',\n",
       " 'cancer',\n",
       " 'canibus',\n",
       " 'cant',\n",
       " 'canvas',\n",
       " 'cap',\n",
       " 'capitalized',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'cares',\n",
       " 'caroline',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'catch',\n",
       " 'catchy',\n",
       " 'categories',\n",
       " 'cats',\n",
       " 'cause',\n",
       " 'caution',\n",
       " 'cazzy',\n",
       " 'cd',\n",
       " 'cd92db3f4',\n",
       " 'ce',\n",
       " 'cease',\n",
       " 'cece',\n",
       " 'celeb',\n",
       " 'celebrate',\n",
       " 'celebrated',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'censor',\n",
       " 'cent',\n",
       " 'central',\n",
       " 'cents',\n",
       " 'cereal',\n",
       " 'certain',\n",
       " 'certification',\n",
       " 'cevxzvsjlk8',\n",
       " 'cge',\n",
       " 'chacking',\n",
       " 'chainise',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'chanel',\n",
       " 'chanell',\n",
       " 'change',\n",
       " 'changeable',\n",
       " 'chanicka',\n",
       " 'channel',\n",
       " 'channels',\n",
       " 'channnnnnelll',\n",
       " 'chanson',\n",
       " 'chap',\n",
       " 'characterized',\n",
       " 'charity',\n",
       " 'charley',\n",
       " 'charlie',\n",
       " 'charlieee',\n",
       " 'chaste',\n",
       " 'chaîne',\n",
       " 'chcfcvzfzfbvzdr',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'cheats',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'cheetos',\n",
       " 'cheilith',\n",
       " 'chesture',\n",
       " 'chhanel',\n",
       " 'chick',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chillpal',\n",
       " 'chills',\n",
       " 'chillstep',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'ching',\n",
       " 'chiptunes',\n",
       " 'choice',\n",
       " 'chooses',\n",
       " 'chorenn',\n",
       " 'chorus',\n",
       " 'chose',\n",
       " 'chrck',\n",
       " 'christ',\n",
       " 'christianity',\n",
       " 'christians',\n",
       " 'christmas',\n",
       " 'chubby',\n",
       " 'chubbz',\n",
       " 'chuck',\n",
       " 'cid',\n",
       " 'cirus',\n",
       " 'citizen',\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the features it extracted from the data\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extracted features from the data. And as we know the models perform well over the numbers and guess what, we've now \n",
    "numbers in the form of array of arrays. And so these numbers i-e 'X' will be act as features while the corresponding labels are stored \n",
    "in the variable 'data_label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for splitting the data into training and testing part\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, data_label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1310x4454 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17525 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 4454)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look we've now 4454 of total features to predict the spam or not spam class of a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1310x4454 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17525 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Standard Naive Bayes Classifier for the Spam filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.95046439628483 %\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 ==> Not spam (Ham)\n",
    "- 1 ==> Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we need to provide the data or say text to the model in vectorize form (as we did) so for the future data or prediction, we should convert that data first into vectorize form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_comment = [\"Click on this link\"]\n",
    "vectorizer_predict = vectorizer.transform(predict_comment).toarray()\n",
    "clf.predict(vectorizer_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_comment_2 = [\"Awesome song love you!\"]\n",
    "# vectorizer_predict_2 = vectorizer.transform(predict_comment_2).toarray()\n",
    "# clf.predict(vectorizer_predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "if clf.predict(vectorizer_predict) == 1:\n",
    "    print('Spam')\n",
    "elif clf.predict(vectorizer_predict) == 0:\n",
    "    print('Not Spam/ Ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC_Model = open(\"NBC_Model.pkl\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, NBC_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC_Model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
